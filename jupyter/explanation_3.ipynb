{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation for problem 3: Huffman Coding\n",
    "\n",
    "## Requirements\n",
    "There were no requirements for this problem.\n",
    "\n",
    "## Code Design\n",
    "I chose to implement this algorithm: https://www2.cs.duke.edu/csed/poop/huff/info/\n",
    "\n",
    "Once I create the tree according to the above mentioned algorithm, I traverse it to create a dictionary that maps letters to their respective binary code (in `map_char_to_binary`). I use that dictionary to encode the data (in `encode_data`).\n",
    "\n",
    "\n",
    "## Efficiency\n",
    "\n",
    "### Time efficiency\n",
    "Given the input data of size `N` (number of characters in the sentence), the following operations are performed:\n",
    "* Calculate the frequency of the letters and create a forest of single node Huffman trees, requires to go through each letter in the sentence: `O(N)`\n",
    "* Merging two trees takes `O(1)`. Before merging, I'm sorting the forest based on the weight of each tree at each iteration. The sorting takes `O(N*log(N))` time. Creating the Huffman Tree then means we we have to do that for `N` single node trees, so the total cost to build the Huffman tree is `O(N^2*log(N))`.\n",
    "* Map the letters to their respective binary form requires `O(N)` in the worst case scenario, when the input data has all unique characters.\n",
    "* Encoding the data is again `O(N)`, since we have to go through each letter in the input data to encode it.\n",
    "* Decoding the tree takes `O(N)`, since we have to go through each letter in the input data.\n",
    "\n",
    "The total cost for time is `O(N^2*log(N))`.\n",
    "\n",
    "This is too high and should be reduced. This can be done by using a min-heap based on the weight of each tree, rather than a list of trees that has to be sorted every time a new tree is inserted.\n",
    "\n",
    "Creating the min-heap will take `O(N*log(N))`, since inserting & deleting require `O(log(N))`, and we have to insert `N` trees. Later, when merging trees, we have to do so `N` times, and each time we delete 2 trees and insert one new tree, thus needing `O(log(N))` for each of these operations, which results in a total of `O(N*log(N))` operations.\n",
    "\n",
    "### Space efficiency\n",
    "We create these data structures to encode and decode data using Huffman trees:\n",
    "* Single Node Huffman trees to begin with, which are later merged into a single Huffman tree containing all letters. Despite the fact that each tree has its own overhead, we can simplify the space efficiency analysis for a large input `N` to be `O(N)` at all times.\n",
    "* When encoding data, we create a hash map that maps the letters to their respective binary code. This will take in the worst case when all letters are unique in the input data: `O(N)`.\n",
    "\n",
    "The total space cost is thus `O(N)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
